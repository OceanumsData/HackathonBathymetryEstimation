{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from torchsummary import summary\n",
    "import os\n",
    "import time\n",
    "\n",
    "from dataset import HackathonDataset\n",
    "from convnet import ConvNet\n",
    "from resnet import ResNet\n",
    "\n",
    "from config import DATA_DIR, DEVICE, USE_RAW, AUTO_ROTATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble:\n",
    "    \n",
    "    def __init__(self, Model, device, n_estimators):\n",
    "        self.Model = Model\n",
    "        self.instances = [self.Model(device) for i in range(n_estimators)]\n",
    "        self.performances = []\n",
    "    \n",
    "    def fit(self, train_dataloader, test_dataloader, n_epochs, print_frequency):\n",
    "        for it, instance in enumerate(self.instances):\n",
    "            print(f\"\\n=== Training instance {it+1}/{len(self.instances)} ===\\n\")\n",
    "            score = instance.fit(train_dataloader, test_dataloader, n_epochs, print_frequency)\n",
    "            self.performances.append(score)\n",
    "    \n",
    "    def predict(self, dataloader, percentage):\n",
    "        good_instances = []\n",
    "        for i in range(len(self.instances)):\n",
    "            index = np.argmin(self.performances)\n",
    "            good_instances.append(self.instances[index])\n",
    "            self.instances.pop(index)\n",
    "            self.performances.pop(index)\n",
    "        predictions = [instance.predict(dataloader) for instance in good_instances]\n",
    "        return np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 3\n",
    "n_estimators = 20\n",
    "print_frequency = 3\n",
    "batch_size = 8  # High batch size often happen to not converge... So we use small batches, even if slower\n",
    "pred_batch_size = 128  # There is no problem of convergence for training batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================NOTE============================\n",
    "# We often have to reset the model, because it won't converge. I don't know why, but it is useful to know\n",
    "# If the training loss is stuck around 22 and the validation loss is stuck around 10,\n",
    "# reset the model by running this cell again, and relaunch training\n",
    "#========================END OF NOTE=====================\n",
    "\n",
    "dataset = HackathonDataset(DATA_DIR + 'mixed_train.csv', DATA_DIR, USE_RAW, transform=True, auto_rotate=AUTO_ROTATE)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=os.cpu_count() - 2)\n",
    "val_dataset = HackathonDataset(DATA_DIR + 'mixed_validation.csv', DATA_DIR, USE_RAW, auto_rotate=AUTO_ROTATE)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=pred_batch_size, shuffle=False, num_workers=os.cpu_count() - 2)\n",
    "model = Ensemble(ConvNet, DEVICE, n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training instance 1/2 ===\n",
      "\n",
      "Epoch 1/1\n",
      "Number of batches viewed : 2373\n",
      "Current training loss : 8.633549655784899\n",
      "Current validation loss : 7.920380415878896\n",
      "Number of batches viewed : 4747\n",
      "Current training loss : 7.390445281400737\n",
      "Current validation loss : 5.449304066305086\n",
      "Number of batches viewed : 7121\n",
      "Current training loss : 6.927971976287443\n",
      "Current validation loss : 6.931379663662647\n",
      "The epoch took  37.17 seconds\n",
      "\n",
      "=== Training instance 2/2 ===\n",
      "\n",
      "Epoch 1/1\n",
      "Number of batches viewed : 2373\n",
      "Current training loss : 8.336663242437345\n",
      "Current validation loss : 6.16724094631165\n",
      "Number of batches viewed : 4747\n",
      "Current training loss : 7.234367855778238\n",
      "Current validation loss : 9.655395601678082\n",
      "Number of batches viewed : 7121\n",
      "Current training loss : 6.954547437982792\n",
      "Current validation loss : 6.247616497550424\n",
      "The epoch took  36.90 seconds\n"
     ]
    }
   ],
   "source": [
    "model.fit(dataloader, val_dataloader, n_epochs, print_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = HackathonDataset(DATA_DIR + 'mixed_test.csv', DATA_DIR, USE_RAW, auto_rotate=AUTO_ROTATE)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=pred_batch_size, shuffle=False, num_workers=os.cpu_count() - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michel/.venvs/ml/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/michel/.venvs/ml/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "image_file_names = []\n",
    "for val in test_dataloader:\n",
    "    image_file_names += val['image_file_name']\n",
    "\n",
    "predictions = model.predict(test_dataloader, 0.6)\n",
    "kaggle_df = pd.DataFrame({'image_id': image_file_names,\n",
    "                          'predicted_z': predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_df.to_csv('predictions/prediction-' + datetime.now().strftime(\"%d-%m-%y:%H-%M\") + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
